\chapter{Прогнозиране на времеви редове с помощта на машинно самообучение}

\section{Прогнозиране на времеви редове}

Времевите редове са последователност от измервания, която следва строг ред във времето \cite{Oliveira-01}. Измерванията най-често са на равни интервали, но не винаги това е възможно или рационално \cite{Shen-01}. Изчислението на прогноза, базираща се на миналите стойности във времевия ред е своеобразна екстраполация \cite{Khashei-03}. При времеви редове, където нови стойности се отчитат твърде бързо във времето (например, едноминутен интервал на FOREX пазара) е нужно инструментът за прогнозиране да се обучава динамично, паралелно с режима за употреба \cite{Wagner-01}. В някои редки случаи, информацията за времевия ред трябва да бъде извлечена от съдържанието на неструктурирани документи \cite{Wang-01}. В началото на 70-те години на XX век \cite{Gooijer-01} се предлагат линейни модели за прогнозиране на времеви редове – авторегресионен (Autoregressive) и плъзгащи средни (Moving Averages) \cite{Tealab-01}. При авторегресионния модел се възприема, че прогнозната стойност е линейна комбинация от стойностите в миналото. При плъзгащите средни прогнозната стойност е функция на случайни смущения - смущения, които са повлияли на времевия ред. Между двата модела е възможна комбинация под формата на авторегресионна интегрирана плъзгаща средна (Auto-Regressive Integrated Moving Average) \cite{Khashei-01}. При определянето на параметрите за авторегресията и интегрираната плъзгаща средна успешно могат да се приложат еволюционни алгоритми \cite{Cortez-01}. Линейните модели се оказват неприложими за множество времеви редове от реалната практика \cite{Bontempi-01}. Изкуствените невронни мрежи се оказват един от подходите да се премине от линейност \cite{Zhang-03} към нелинейност в моделите. Трудностите при изкуствените невронни мрежи са свързани с по-големия брой параметри, които са трудни за определяне, като степен за обучение (learning rate) при обратно разпространение на грешката или размер на скрития слой \cite{Tang-01}. В някои разработки се правят опити да се автоматизира определянето на параметрите \cite{Yan-01}. Липсата на систематизиран подход за изграждане на изкуствени невронни мрежи \cite{Qi-01} е пряко свързан с определянето на параметрите. Линейност и нелинейност могат да се съчетаят в хибридни реализации, базирани на плъзгащи средни и изкуствени невронни мрежи \cite{Zhang-01}. Недостатък при изкуствените невронни мрежи е нуждата от по-голям брой тренировъчни примери \cite{Lachtermacher-01}. Освен броя на тренировъчните примери, изключително съществен параметър се явява размерът на входния слой, който определя прозореца от стойности в миналия периода от миналото \cite{Chen-01}. С добавяне на обратни връзки в изкуствените невронни мрежи се постига ефект на кратковременна памет. Ефектът на кратковременната памет в изкуствените невронни мрежи често води до подобряване на получените прогнози \cite{Cao-02}. Ускорение в процеса по обучението на изкуствени невронни мрежи може да се получи чрез използването на вероятностни невронни мрежи (Probabilistic Neural Networks) \cite{Khashei-02}. Комбинацията от линейни уравнения за постигането на разграничение при нелинейни класове се постига и чрез машина с поддържащи вектори (Support Vector Machines) \cite{Kyoung-jae-01}. Машините с поддържащи вектори се явяват подобрение на изкуствените невронни мрежи, обучавани по правилото за обратно разпространение на грешката. Времето за обучение се намалява, докато достоверността на прогнозите се увеличава \cite{Tay-01}. Ефективността на машините с поддържащи вектори може да се подобри, когато се използват алгоритми за адаптиране на параметрите \cite{Cao-01}. При времеви редове с ясно изразен тренд и сезонност \cite{Zhang-04}, премахването им може да подобри възможностите за генериране на прогноза \cite{Zhang-02}, включително и в комбинация с изкуствени невронни мрежи \cite{Jain-01}. От оригиналния времеви ред се изваждат стойностите на тренда и подбрани циклични функции \cite{Nelson-01} или уейвлети \cite{Joo-01}. При слабо изразена сезонност, по-удачно може да се окаже сезонността да не се премахва \cite{Hamzacebi-01}. Възможност за генериране на прогнози дават и алгоритмите за разпознаване на образи (Patterns Recognition). Времевият ред може да бъде изследван за наличието на конкретни шаблони/образи и прогнозата да се разпознава на появата на конкретен шаблон \cite{Singh-01}. При много зашумени времеви редове е удачно да се приложи предварителна обработка на данните, така че шумът да се премахне или редуцира \cite{Lu-01}.

\section{Обучение на изкуствени невронни мрежи}

Най-разпространеният вид изкуствени невронни мрежи е многослойният перцептрон. Структурата им е под формата на насочен тегловен граф, който може да има различни конфигурации \cite{da-Silva-01}. Организацията е на слоеве \cite{Jain-02} (най-често три - входен, скрит и изходен \cite{Pradhan-01}), като най-популярната практика е всички възли между два съседни слоя да са пълно свързани по между си. Пълната свързаност между слоевете понякога се нарушава с цел по-ефективно обучение \cite{Mocanu-01}. Този тип мрежи се използват за решаването на задачи, в които са налични тренировъчни примери. Такъв тип обучение е известно като обучение с учител. Целта на изкуствената невронна мрежа е по входно-изходните двойки (тренировъчни примери) да формира функционална зависимост \cite{Kattan-01}. Този механизъм на работа прави многослойните перцептрони идеални за решаване на задачи за класификация \cite{Kubat-01} или прогнозиране \cite{Basheer-01}. Прогнозирането във финансовия свят е задача с голяма сложност при силна нелинейност, зависеща от много и различни фактори \cite{Bing-01}. Процесът на самото обучение се състои в намирането на такива стойности за теглата в графа, че изкуствената невронна мрежа максимално добре да онагледява зависимостта между входните данни и изходните данни, без това да доведе до пренапасване (overfitting) \cite{Bilbao-01}. Задачата е оптимизационна и е дефинирана в многомерни нелинейни пространства \cite{Kingston-01}. Най-често началните стойности на теглата се избират случайно в близка околност около нулата, но е възможно първоначалните стойности да се определят с някаква форма на евристика, например генетични алгоритми \cite{Chandwani-01}. Теглата на мрежата най-често участват в линейна комбинация с входните сигнали. Получената сума се подлага на нормиране, чрез прилагане на прагова функция (функция на активация) \cite{Ertugrul-01}. Предварителна обработка на данните, преди да бъдат подадени на входа на изкуствената невронна мрежа, често подобряват процеса на обучението \cite{Nawi-01}. Липсващи стойности в множеството от входни данни оказват влияние при процеса на обучението на изкуствената невронна мрежа \cite{Viharos-01}. Организация от три слоя е една от най-често използваните в съчетание с точен числен метод за обучение наречен обратно разпространение на грешката \cite{Pomerleau-01}. Алгоритъмът с обратно разпространение на грешката дава възможности да бъде подобряван по различни начини \cite{Kollias-01}, което най-много се налага заради склонността да попада в локални минимуми \cite{Chen-02}. Освен точни числени методи, при обучението на изкуствени невронни мрежи приложение намират и стохастичните еволюционни методи \cite{Slowik-01}, които често са вдъхновени от природни феномени \cite{Cui-01}. Точните числени методи превъзхождат евристичните по ефективност на обучението \cite{Piotrowski-01}, но евристичните методи дават повече възможности за избягване на локални оптимуми. Също така, градиентните точни числени методи изискват диференцируеми функции \cite{Karaboga-01}, което спомага в търсенето на глобални оптимуми \cite{Roy-01}. Популационните евристични методи имат много висока степен за паралелна обработка и са изключително подходящи при паралелни изчисления \cite{Ding-01} или разпределени изчисления. Добавянето на случаен шум (например, нормално разпределен \cite{Zur-01}) може значително да подобри процеса по обучението на многослойни изкуствени невронни мрежи \cite{Sietsma-01}. Случайното изключване на различни възли от скрития слой също може да доведе до подобрено обучение \cite{Sequin-01}. Освен изключването на неврони, възможно е обучението да започва с по-голяма по размер мрежа, а с времето размера да се намалява (алгоритъм за подрязване) \cite{Karnin-01}. Противоположно на намаляването е подхода за избор на мрежова топология чрез нарастване \cite{Yao-01}. В някои ситуации нарастването на размера на изкуствената невронна мрежа води до експоненциално нарастване на нужните за обучението изчислителни ресурси \cite{Wilamowski-01}. Ранно спиране на обучението също може да подобри обобщаващите свойства на изкуствената невронна мрежа \cite{Coulibaly-01}.

\section{Евристични оптимизационни алгоритми}

Двете основни направления в глобалните оптимизационни алгоритми са точните числени методи и евристичните. При точните числени методи най-често се използва пресмятането на градиент и следването му. Те често са неприложими за нелинейни проблеми \cite{Koziel-01} или в зашумени входни данни \cite{Beyer-02}. При евристичните методи за глобална оптимизация (еднокритериална или многокритериална \cite{Cheng-01}) се залага на някаква евристика (интуитивно очакване) за намиране на решения по-близки до глобалните оптимуми (не се гарантира достигането на глобалния оптимум \cite{Coello-02}), като приложението е в множество области \cite{Slowik-02}, в които точните числени методи не биха дали разумен резултат в приемливо време. Възможностите в евристиките са толкова големи, че евристични алгоритми може да се ползват за проектиране на евристични алгоритми \cite{Diosan-01}. Целта при евристичните методи е да се постигне глобална сходимост \cite{He-02} в търсене на оптимално решение \cite{Beyer-01}, което понякога се постига и с комбинация от евристики \cite{Grosan-01}, като дори в такава конфигурация евристиките не винаги са достатъчно ефективни \cite{He-01}. Евристичните методи много често се реализират с помощта на генерирани случайни числа (така наречената генериране-тестване стратегия \cite{Yao-02}), генератори на псевдо-случайни числа \cite{Kazimipour-01} (чувствителни по отношение на началната инициализация \cite{Eiben-02}) или хаотични последователности \cite{Caponetto-01}. Докато за определени части от евристиката има теоретична обосновка, то в повечето случаи се използват и параметри, за които няма теоретична обосновка, а се избират стойности по подразбиране (например, вероятността за кръстосване и вероятността за мутация при генетичните алгоритми) \cite{Eiben-01}. Един от подходите за избор на стойности за параметрите е преди стартирането на изчисленията, а другия подход е адаптивна промяна на стойностите, по време на самото изпълнение. В някои разработки евристични оптимизационни методи се използват за настройка на параметрите при евристична глобална оптимизация. Чрез локално търсене може да се прави фина настройка на параметрите в самия процес по оптимизация \cite{Karafotias-01}, както и чрез статистически анализ \cite{Francois-01}. Когато евристичните методи се базират на множество от кандидат решения (популация), то те спадат към групата на популационните евристични алгоритми \cite{Whitley-01}. Популацията може да е организирана в еволюционен процес (например, генетични алгоритми или еволюция на разликите) или в поведение на индивидите (например, колония на мравките и рояк от частици) \cite{El-Abd-01}. Най-честият подход за попълване на популацията в началото е на случаен принцип, но са възможни и решения с предварително подбрани индивиди \cite{Coello-01}. Всеки индивид в популацията представлява вектор от пространството на променливите (цели или дробни числа \cite{Kachitvichyanukul-01}). Този вектор може да бъде с фиксирана или с плаваща дължина \cite{Ryerkerk-01}. Генетичното разнообразие в популацията може да бъде ключов фактор за ефективен оптимизационен процес \cite{Ursem-01}. При случаите, в които наличната популация не съдържа достатъчно разнообразни решения, така че някои решения в пространството на търсенето стават недостижими, може да се приложи схема за въвеждане на изцяло новосъздадена популация \cite{Wegener-01}. Наличието на множество кандидат решения и появата на нови кандидат решения в процеса на оптимизация, често води до забавяне в оценката на решенията, най-вече когато целевата функция се изчислява бавно. При бавни за пресмятане целеви функции \cite{Naudts-01} е разумно да се търсят някакви начини за ускорена оценка на кандидат решенията \cite{Salami-01}. В процеса на евристична оптимизация може да се приложи изследване на пространството и апроксимация с експериментално определено вероятностно разпределение да ускори намирането на оптимално или субоптимално решение \cite{Kern-01}. Едно от най-големите предимства на популационните алгоритми е възможността да се изпълняват паралелно или в разпределена среда \cite{Vikhar-01}. Дори, когато изпълнението се извършва с програмни средства за паралелна обработка, но не еднопроцесорна машина, някои популационни алгоритми дават по-добри резултати, спрямо последователната версия на кода \cite{Alba-01}. При оптимизационни проблеми с наложени ограничения (особено нелинейни ограничения), допълнителни мерки трябва да се вземат при генерирането на недопустими решения и разрешаването на такива решения да бъдат част от популацията \cite{Lagaros-01}.

\section{Изчисления в разпределена среда}

Една значителна част от съвременните алгоритми са изцяло линейни. Това означава, че всяка следваща инструкция зависи от резултатите пресметнати в предходната инструкция. Тази особеност не позволява линейните алгоритми да бъдат изпълнявани на повече от едно аритметично-логическо устройство. Единственият начин за ускоряване на пресмятанията при линейните алгоритми е чрез скъсяване на времето, за което се изпълняват различните инструкции. Друга, доста по-малка част от съвременните алгоритми, позволяват различни групи от инструкции да се пресмятат едновременно. Идеята е по-големите задачи да се раздробяват на по-малки \cite{Mendivil-01}, които да се решават едновременно. Един от най-популярните примери е бързото сортиране (QuickSort). Алгоритъмът при бързото сортиране е свързан с първоначално разделяне на масива на две части. След първия пас при възходящо сортиране, лявата част съдържа по-малките елементи, а дясната част по-големите елементи. На свой ред, двете части на масива се възприемат като два разбъркани независими масива. Всяка от двете половини може да се подаде на различно ядро или процесор за пресмятане. От двете половини се получават четири нови подмасива, след това осем подмасива и т.н. От една страна, бързото сортиране има рекурсивна природа, но от друга страна то е идеален кандидат за паралелни пресмятания. Раздробяването на половини може да продължи докато се натоварят всичките налични ядра/процесори. Те заедно работят над обща памет, тъй като няма припокриване между подмасивите. Групата на паралелните алгоритми са подходящи за изпълнение на многопроцесорни системи \cite{Topping-01}, които споделят обща памет. Стъпка напред в децентрализираното пресмятане, е когато различните процесори са в отделни изчислителни машини, които разполагат със своя собствена памет. Този вид пресмятания се организират в клъстъри \cite{Desell-02}. Често клъстърите са съставени от еднотипни изчислителни машини \cite{Qu-01}, но това не е задължително условие \cite{Wang-02}. При свързването на няколко клъстъра и/или супер компютри се формира изчислителен грид (Grid Computing) \cite{Tiwari-01}. Когато изчислителните машини териториално се намират на различни места и контрола върху тях се осъществява от различни хората, изчисленията са в разпределена среда и в почти всички случаи изчислителните машини са различни \cite{Kattan-02}. Някои нискобюджетни проекти не могат да си позволят наемането на голям брой изчислителна техника \cite{Merelo-Guervos-01} и в такава ситуация се създават дарени изчисления в разпределена среда (Donate/Volunteer Distributed Computing) \cite{Varacha-01}. При дарените разпределени изчисления, хора ентусиасти (броят участници може да е много голям \cite{Castillo-01}) преотстъпват изчислителната си техника безвъзмездно \cite{Cole-01}, така с нея да се извършват изчисления в периодите на занижена употреба. Поради липсата на контрол върху изчислителните машини, надеждността на пресметнатите резултати е винаги под съмнение \cite{Desell-04}. Много често такъв вид проекти се реализират под формата на скринсейвъри (Screensavers). Скринсейвърите се появяват заедно с катодно лъчевите тръби при мониторите и задачата им е била да съхраняват покритието на монитора в периоди, в които потребителят не използва компютърната си система. Активацията на скринсейвъра е ясен индикатор, че компютърната система преминава в състояние на намалена употреба. Наличието на скриптови езици \cite{Rivas-01} в уеб браузърите дава възможност за навлизането и на уеб разпределените изчисления \cite{Duda-01}. С масовото навлизане на мобилните устройства през последните петнадесет години, се разкриха нови възможности за дарени изчисления в разпределена среда \cite{Gong-01}, които се извършват на умни телефони или таблети, докато те са в режим на занижена употреба. Основно предимство на мобилните устройства е, че те работят в непрекъснат режим от 24/7, но пък това е свързано с недостатъка, че изчислителната мощност е значително по-ниска в сравнение със съвременна настолна компютърна система. 

Възможността изкуствените невронни мрежи да се обучават с еволюционни алгоритми \cite{Desell-03} (обичайно много времеемък процес \cite{Guo-01}), понякога комбинирани с обратно разпространение на грешката \cite{Zhu-01}, позволява ефективната реализация на такова обучение в разпределена среда \cite{Pandey-01}. Най-често глобалната популация се разпределя на множество машини \cite{Plagianakos-01}, като локални популации и решения мигрират между машините \cite{Tan-01}. Другият подход е различни задачи да се възлагат на отделните изчислителни машини \cite{Altinoz-01}. Стратегията за възлагане на отделни изчислителни задачи \cite{Ahmad-01} в разпределената среда, от своя страна, също може да е осъществена с еволюционни евристични алгоритми \cite{Sharma-01}. Освен оптимизация на теглата в мрежата е възможна и оптимизация на структурата ѝ \cite{Desell-01}. Характерно за разпределените изчисления е високата консумация на електрическа енергия \cite{Foo-01} и увеличаване на въглеродния отпечатък \cite{Kumar-01}. Обучението на изкуствени невронни мрежи с еволюционни алгоритми може да се реализира и в разпределена среда със специализиран хардуер \cite{Epitropakis-01}. При евристичните алгоритми (особено еволюционните и/или популационните) най-често се залага на многократно изчисляване на целевата функция. Общото правило е, че евристиките са ефективни за задачи, в които целевата функция се пресмята бързо. В реалната практика обаче, често целевата функция е най-бавната част от оптимизационния процес. Точно при такива задачи изчисленията в разпределена среда са най-силният инструмент \cite{Liu-01}. Разпределянето на пресмятанията не води до 100\% ускорение, тъй като има допълнителна работа при синхронизацията на резултатите и комуникацията в мрежата \cite{Gong-01}. Повечето съвременни програмни езици са обектно-ориентирани. В това число влиза и JavaScript, макар и там да няма класове, но все пак се работи с обекти. При реализацията на разпределени изчисления една част от програмните езици разчитат на бинарна сериализация на обектите и разпращането им по мрежата (например, RMI, DCOM или CORBA) \cite{Ding-02}. Бинарната сериализация има редица недостатъци, така че в уеб базираните приложения и в RESTful приложенията се залага на описателна серизализация (например, JSON или XML). При използването на JSON, релациите съхранени в релационната база данни се оформят като JSON комуникационен пакет и от страната на клиента, ако това е JavaScript, директно биват използвани във формата на JavaScript обекти. Когато клиентското приложение не е JavaScript, се преминава през Parser, трансформиращ структурираната текстова JSON информация в обект за съответния програмен език. 

\section{Дискусия и изводи}

Изработването на прогнози е от голяма важност за съвременните общества, като започнем от прогноза за метеорологичната обстановка и стигнем до прогнози за промяната на цените за стоки, акции и валути. В случая с прогнозирането на цени, данните успешно се представят във формата на времеви ред. Съвсем логично, всяка следваща стойност да има някаква зависимост от предходните стойности. През последните десетилетия са разработени много начини за прогнозиране на финансови времеви редове, но като един от най-обещаващите се открояват изкуствените невронни мрежи. Характерно за изкуствените невронни мрежи е, че те са много ефективен инструмент, след като веднъж са обучени. Процесът на обучение, от своя страна, често отнема твърде дълго време и се нуждае от голямо количество изчислителни ресурси. Един от най-използваните начини за обучение на изкуствени невронни мрежи е алгоритъмът с обратно разпространение на грешката. Този алгоритъм спада към групата на точните числени, градиентни алгоритми. Негови слабости са невъзможността да бъде ефективно реализиран в паралелни изчисления и склонността му да изпада в локални оптимуми, без да има ефективни способи за избягването им. Алгоритъмът за обратно разпространение на грешката много добре се допълва с евристичните, еволюционни алгоритми за глобална оптимизация. Характерното за този вид евристики е, че те се поддават на изключително висока степен за паралелна обработка. Някои от тези евристики са специално създадени за избягване на локалните оптимуми. Широките възможностите за паралелна обработка при еволюционните и популационните евристики позволяват реализацията им на хетерогенни системи за разпределени изчисления. С цел за по-висока финансова ефективност, този вид разпределени изчисления могат да се изпълняват на принципите за дарената изчислителна мощност. Наличието на значително повече мобилни устройства (умни телефони и таблети), спрямо настолните компютърни системи, води до мотивация пресмятанията да се реализират под формата на мобилни разпределени изчисления.

Всичко изброено до тук, дава основанието да се търси реализация на система за мобилни разпределени изчисления, която обучава изкуствени невронни мрежи, с хибриден алгоритъм (обратно разпространение на грешката и популационна глобална оптимизация), за прогнозиране на финансови времеви редове.

Обобщената информацията от направения обзор е представена в Таблица \ref{tab000101}.

\begin{table}[h!]
%%\begin{center}
    \begin{tabular}{ | c | c | c |}
      \hline
        & \thead{Точно числени методи\\ за обучение} & \thead{Евристични методи\\ за обучение} \\
      \hline
      \cellcolor{gray!15}
      Вид &  \thead{Обратно разпространение на грешката; \\ Еластично обратно разпространение\\ на грешката; \\ Манхатън обучение; \\ Метод на конюгиран градиент.}  & \thead{Еволюция на разликите; \\ Генетичен алгоритъм; \\ Еволюционна стратегия.}  \\
      \hline
      \cellcolor{gray!15}
      Приложение & \makecell{Работят добре при решаване на\\ задачи с по-ниска сложност.} & \makecell{Възможност за паралелна \\ обработка или\\ разпределени изчисления; \\ Прилагат се там, където\\ точните числени методи не\\ дават резултата в\\ приемливо време.}  \\
      \hline
      \cellcolor{gray!15}
      Особености &  \makecell{Изискват диференцируеми\\ функции}  & \makecell{Могат да се използват\\ при прекъснати функции,\\ стъпаловидни функции и\\ функции без дефинирана\\ производна в определени\\ области.}  \\
      \hline
      \cellcolor{gray!15}
      Недостатъци &  \makecell{Склонност да попада в\\ локален оптимум;\\ Трудно се организират\\ в паралелни или \\разпределени изчисления.}  & \makecell{Обучението може да отнеме\\ много  време. Целевата\\ функция се пресмята бавно,\\ което е основна причина за\\ забавянето.}  \\
      \hline
      \cellcolor{gray!15}
      Предимства &  \makecell{Значително по-бърза\\ сходимост на процеса по\\ обучение, стига да не се\\ попадне в локален оптимум.}  & \makecell{Спомагат за избягването\\ на локални оптимуми.}  \\
      \hline
    \end{tabular}
    \caption{Обобщение на точните и евристичните методи за обучение}
	\label{tab000101}
%\end{center}
\end{table}